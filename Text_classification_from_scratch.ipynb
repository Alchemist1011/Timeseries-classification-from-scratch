{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TME_KWjrBvza"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load DataSet**"
      ],
      "metadata": {
        "id": "uKp6swQ_CQMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbywJ6U7CTuU",
        "outputId": "96420dc7-72db-4d7b-a471-78859b6c4341"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  18.1M      0  0:00:04  0:00:04 --:--:-- 18.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFUEykTPCfbG",
        "outputId": "404e2e08-d804-4aff-e8ab-5905883e1ad8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9du6kPxKCfYg",
        "outputId": "dd43c0cc-5ca7-4517-8826-6389608a2bc1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aGrYnO1CfVg",
        "outputId": "7d3be8d2-b9ed-46ea-d2c5-3136a97db09e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  unsup  unsupBow.feat  urls_neg.txt  urls_pos.txt  urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/6248_7.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ2B52RYCfSO",
        "outputId": "52bbd7dc-71fd-4f47-f4fc-b62b74bc7e6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "X9syzd6zCfPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "raw_train_ds =tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhH8oC1wCfMO",
        "outputId": "b1abc3bb-e1c8-4e29-b596-d6599d14e460"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 75000 files belonging to 3 classes.\n",
            "Using 60000 files for training.\n",
            "Found 75000 files belonging to 3 classes.\n",
            "Using 15000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in raw_train_ds: 1875\n",
            "Number of batches in raw_val_ds: 469\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bCFhDNcCfI-",
        "outputId": "fb9ce7b7-fd63-46af-bae5-b4e2b6702935"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'SPOILERS: We sit through ten minutes of AWFUL clich\\xc3\\xa9d dialog at the beginning from two completely unoriginal characters with bad twangs (ripped off from Kalifornia and Natural Born Killers - there isn\\'t an original thing about these two) and you\\'re going \"either they\\'re about to kill everyone in the diner or already have\" and lo and behold guess what happens.<br /><br />I can\\'t stand all the Tarantino wannabes out there and this guy is one of the worst. I got maybe 25-30 minutes into the thing when I just couldn\\'t take it and stopped watching. Miner\\'s really bad acting was unbearable - I couldn\\'t take it. That, and the terrible script. After reading some of these comments I see there was a big twist - well guess what? No one cares. When you create completely uninteresting, unoriginal and unlikeable character like these two clich\\xc3\\xa9s, no one cares what big \"twist\" may have happened. I hope this is the end of these types of movies.'\n",
            "2\n",
            "b'This movie is horrible- in a \\'so bad it\\'s good\\' kind of way.<br /><br />The storyline is rehashed from so many other films of this kind, that I\\'m not going to even bother describing it. It\\'s a sword/sorcery picture, has a kid hoping to realize how important he is in this world, has a \"nomadic\" adventurer, an evil aide/sorcerer, a princess, a hairy creature....you get the point.<br /><br />The first time I caught this movie was during a very harsh winter. I don\\'t know why I decided to continue watching it for an extra five minutes before turning the channel, but when I caught site of Gulfax, I decided to stay and watch it until the end.<br /><br />Gulfax is a white, furry creature akin to Chewbacca, but not nearly as useful or entertaining to watch. He looks like someone glued a bunch of white shag carpeting together and forced the actor to wear it. There are scenes where it looks like the actor cannot move within, or that he\\'s almost falling over. Although he isn\\'t in the movie that much, the few scenes are worth it! Watch as he attempts to talk smack to Bo Svenson, taking the Solo-Chewbacca comparison\\'s to an even higher level! <br /><br />I actually bought this movie just because of that character, and still have it somewhere! <br /><br />Gulfax may look like sh!t, but he made this movie!!! The only reason I\\'ve never seen the sequel, or even sought it out, was because of his absence! Perhaps should there be a final film, completing the trilogy, Gulfax will make a much-anticipated return!'\n",
            "1\n",
            "b\"Pierce Brosnan has sipped his last Martini and returns, in an outrageous self-parody, as the aging foul-mouthed boozy assassin Julian Noble, who has a particular fondness for teenage girls, bullfights and tacky clothes. During a job in Mexico City he meets Danny (Greg Kinnear), a straight-faced Denver suburban business-man, who's in town to make his deal of-a-life-time, in a hotel bar. Despite their completely different personalities and Julian's crude and insensible remarks, they become friends. <br /><br />Largely carried by the performances of Pierce Brosnan and Greg Kinnear, director Richard Shepard revealed that he didn't write the film with Pierce Brosnan in mind , but I can hardly imagine this without him. He proves to have a real talent for comedy and can be more than just James Bond or cold-war spies. The scene in which the two meet at a glossy hotel bar (stunning sets and beautifully photographed) really is a bravura piece of acting skills. The scene lasts almost fifteen minutes, and although it was probably carefully scripted, the two actors are largely improvising, but they succeed wonderfully! It almost feels like a new standard in screen acting. Think of Robert De Niro and Harvey Keitel in MEAN STEETS improvising and add one of the most subtle underpinnings of many genre clich\\xc3\\xa9s and the actors' own typecasting (Brosnan's James Bond in particular), and you got one of the most delightful pairings in recent Hollywood. <br /><br />Sadly, the story wears thin after a while. After an hour, the film just runs out of steam. Nevertheless, and I can't put my finger on it exactly, I did enjoy this very much. It just feels very fresh and original, with some imaginative use of sets and lighting, and some hints to Seijun Suzuki and Jean-Pierre Melville. The other characters aren't given much to do, but this film does offer something new, in that respect it almost effortlessly succeeds in blending all conventional genres into quite an entertaining spoof. Very amusing.<br /><br />Camera Obscura --- 7/10\"\n",
            "1\n",
            "b\"I hadn't seen this show until it was repeated on Dave. I became aware of it after seeing The Comedy Store Players, a group of comedians which includes Josie Lawrence.<br /><br />I enjoy the unpredictability of Whose Line is it Anyway and the diversity of the performers. The fact that the show had both English and American comedians made it better.<br /><br />The best performance ever had to be when Josie Lawrence and Caroline Quentin sung a duet about a beached whale. Admitedly that description may not sound funny, but if you've seen it you'll know how good it was.<br /><br />Colin Mochrie and Ryan Stiles were a great double act. They were particularly good at the round where they were given two completely random lines to incorporate into a sketch.<br /><br />Other improv shows such as Mock The Week are good, but Whose Line is it Anyway will always be the king of Improvised Comedy shows\"\n",
            "2\n",
            "b'This film, directed by New World Pictures alumnus Jonathan Kaplan and starring cult favorite Aimee Graham, is part of the \"Rebel Highway\" series of remakes of 1950s juvenile-delinquent films.<br /><br />For what was basically a chance for the filmmakers to have fun, _Reform School Girl_ is quite watchable. There are the allusions to McCarthyism characteristic of the \"Rebel Highway\" series (and a well-done general 50s ambiance), and the usual array of interesting types we meet in women-in-prison films. This one is nowhere near as graphic as a typical entry in that genre, but there is one lesbian love scene that is strikingly filmed and acted, suprisingly graphic for such young-looking actresses, and really kind of a tonal shift from the rest of the film. Unfortunately, the film never really resolves the lesbian relationship.<br /><br />The only time I really cringed was the scene where Donna (Aimee Graham) started dancing and singing with the mop, and the camera began moving around and getting in the faces of the onlookers. This was a totally ridiculous scene (but I guess it\\'s hard to pad these things out to 80 minutes).<br /><br />Graham is stellar in the title role, a girl who has had to deal with abuse and, while in reform school, awakens to more positive sexual experiences. I really wish Hollywood would take more notice of her.'\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Data**"
      ],
      "metadata": {
        "id": "kpiUGJQ6DozX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Model constants.\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "vectorize_layer = keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "\n",
        "# Let's make a text-only dataset (no labels):\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)\n",
        "# Let's call `adapt`:\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "naUP11wzCfGP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vectorize Data**"
      ],
      "metadata": {
        "id": "_hGlxbh1EKYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "\n",
        "# Vectorize the data.\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "mtrPuOKMCfDO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buil Model**"
      ],
      "metadata": {
        "id": "1HPD_2-3ERNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "#\n",
        "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs, predictions)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rez17Q9oCe9-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "6Rb5xB0bEbOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "\n",
        "# Fit the model using the train and test datasets.\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwffVmlbCe7H",
        "outputId": "9a09a0c9-3944-446c-f76a-b3e5e0454991"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: -367378399232.0000 - accuracy: 0.1664 - val_loss: -1952958906368.0000 - val_accuracy: 0.1677\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: -14041437175808.0000 - accuracy: 0.1664 - val_loss: -35202432761856.0000 - val_accuracy: 0.1677\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: -93889864138752.0000 - accuracy: 0.1664 - val_loss: -170438009290752.0000 - val_accuracy: 0.1677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bbe136463b0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "jcRyiMt1EjFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qogX06X9Ce4G",
        "outputId": "c2909b29-de44-478c-bb40-267ebb6c7fb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 4ms/step - loss: 172416378601472.0000 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[172416378601472.0, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "# Turn strings into vocab indices\n",
        "indices = vectorize_layer(inputs)\n",
        "# Turn vocab indices into predictions\n",
        "outputs = model(indices)\n",
        "\n",
        "# Our end to end model\n",
        "end_to_end_model = keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Test it with `raw_test_ds`, which yields raw strings\n",
        "end_to_end_model.evaluate(raw_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIAYDd4Ce1P",
        "outputId": "42f51314-a1ff-44fc-bb74-0dc53a938f2e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 172416563150848.0000 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[172416563150848.0, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgje6TarCeyO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}